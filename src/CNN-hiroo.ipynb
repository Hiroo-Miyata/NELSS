{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4335c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# get filename_list\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "788a93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('../data/preprocessed/hiroo-cnn-own.mat')\n",
    "## load\n",
    "eeg = mat[\"eegData\"]\n",
    "emotions = mat[\"labels\"]\n",
    "emotions = emotions.astype(int)\n",
    "nchannel = eeg.shape[1]\n",
    "ntrial = eeg.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b987377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29440, 29, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e6b680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29440, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5287218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAugmentation(matrix, labels, DATAPOINT, STRIDE_SIZE, fs): ## able to improve\n",
    "    n_size = int((matrix.shape[0] - DATAPOINT) // STRIDE_SIZE) + 1\n",
    "    augmentedMat = np.empty((n_size*matrix.shape[2], 1, DATAPOINT, matrix.shape[1]))\n",
    "    augmentedLabel = np.empty((n_size*matrix.shape[2]))\n",
    "    print(matrix.shape[-1], n_size, matrix.shape)\n",
    "    for t in range(matrix.shape[-1]):\n",
    "        trial = matrix[:, :, t]\n",
    "        for i in range(n_size):\n",
    "            augmentedMat[i+t*n_size, :, :, :] = trial[i*STRIDE_SIZE:i*STRIDE_SIZE+DATAPOINT, :]\n",
    "            augmentedLabel[i+t*n_size] =  np.mean(labels[i*STRIDE_SIZE:i*STRIDE_SIZE+DATAPOINT, t])\n",
    "    return augmentedMat, augmentedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b0128cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 226 (29440, 29, 3)\n"
     ]
    }
   ],
   "source": [
    "ans, lab = dataAugmentation(eeg, emotions, 640, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d1a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 1],\n",
       "       [2, 4, 1],\n",
       "       [2, 4, 1],\n",
       "       ...,\n",
       "       [1, 4, 1],\n",
       "       [1, 4, 1],\n",
       "       [1, 4, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "daccb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class EmotionDataManager(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.df = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = torch.tensor(self.label[index]).float()\n",
    "        data = torch.tensor(self.df[index]).float()\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a91a9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## (1, 640, 28)\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=(16, 8), stride=(4,2), padding=(6,3)),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1)\n",
    "                                  )\n",
    "        ## (16, 160, 14)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=(16,4) , stride=(4,2), padding=(6, 1)),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1),\n",
    "                                  )\n",
    "        \n",
    "        ## (32, 40, 7)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=(8,3) , stride=(4,3), padding=(2, 1)),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1),\n",
    "                                  )\n",
    "        ## (64, 10, 3)\n",
    "#         self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=(8,1) , stride=(2,1), padding=(3, 0)),\n",
    "#                                    nn.BatchNorm2d(64),\n",
    "#                                    nn.ReLU(inplace=True),\n",
    "#                                    nn.MaxPool2d(1),\n",
    "#                                   )\n",
    "        ## (64, 40,3)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.50)\n",
    "#         self.dropout2 = torch.nn.Dropout(p=0.50)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(64 * 10 *  3, 128),nn.ReLU(inplace=True),)\n",
    "#         self.fc2 = nn.Sequential(nn.Linear(1024, 64),nn.ReLU(inplace=True),)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "#         x = self.conv4(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x= self.dropout1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x= self.dropout2(x)\n",
    "#         print(x[:, :5])\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49bfe079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(outputs, labels, bw):\n",
    "    outputs = outputs.reshape(-1)\n",
    "    labels = labels.reshape(-1)\n",
    "    c1 = outputs > labels-bw\n",
    "    c2 = outputs < labels+bw\n",
    "    result = np.zeros(c1.shape, dtype=bool)\n",
    "    for i in range(len(c1)):\n",
    "        if c1[i]  and c2[i]:\n",
    "            result[i] = True        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c70b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 901 (29440, 29, 3)\n"
     ]
    }
   ],
   "source": [
    "## Input\n",
    "fs = 128\n",
    "tw = 5\n",
    "DATAPOINT = fs*tw\n",
    "STRIDE_SIZE = fs//4\n",
    "X, Y = dataAugmentation(eeg, emotions, DATAPOINT, STRIDE_SIZE, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2695dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 181 (6400, 29, 10)\n"
     ]
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('../data/preprocessed/hiroo-cnn.mat')\n",
    "## load\n",
    "eeg = mat[\"eegData\"]\n",
    "emotions = mat[\"labels\"]\n",
    "emotions = emotions.astype(int)\n",
    "nchannel = eeg.shape[1]\n",
    "ntrial = eeg.shape[2]\n",
    "X2, Y2 = dataAugmentation(eeg, emotions, DATAPOINT, STRIDE_SIZE, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e803779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape, X.shape\n",
    "X = np.concatenate((X,X2), 0)\n",
    "Y = np.concatenate((Y,Y2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e80ffdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4513, 1, 640, 29), (4513,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4fd77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=2.151967259457237, accuracy=0.1994459833795014\n",
      "test  mean loss=1.7880101378177884, accuracy=0.1362126245847176\n",
      "epoch 2\n",
      "train mean loss=2.06078685749931, accuracy=0.21578947368421053\n",
      "test  mean loss=1.76112846045003, accuracy=0.2779623477297896\n",
      "epoch 3\n",
      "train mean loss=1.9844482125998204, accuracy=0.1994459833795014\n",
      "test  mean loss=1.7723416109813803, accuracy=0.2956810631229236\n",
      "epoch 4\n",
      "train mean loss=1.9929241000780438, accuracy=0.1961218836565097\n",
      "test  mean loss=1.7227103063302447, accuracy=0.13953488372093023\n",
      "epoch 5\n",
      "train mean loss=1.9858956397735512, accuracy=0.1997229916897507\n",
      "test  mean loss=1.7918803953253153, accuracy=0.12181616832779624\n",
      "epoch 6\n",
      "train mean loss=1.9639049794205008, accuracy=0.2027700831024931\n",
      "test  mean loss=1.708749811250638, accuracy=0.1273532668881506\n",
      "epoch 7\n",
      "train mean loss=1.938202067029113, accuracy=0.19889196675900278\n",
      "test  mean loss=1.7134661373505957, accuracy=0.17940199335548174\n",
      "epoch 8\n",
      "train mean loss=1.930965872682693, accuracy=0.19473684210526315\n",
      "test  mean loss=1.818235306512742, accuracy=0.12292358803986711\n",
      "epoch 9\n",
      "train mean loss=1.930709991032397, accuracy=0.20470914127423823\n",
      "test  mean loss=1.7025098705608583, accuracy=0.18161683277962348\n",
      "epoch 10\n",
      "train mean loss=1.9319598094908486, accuracy=0.19889196675900278\n",
      "test  mean loss=1.7173789226071514, accuracy=0.2779623477297896\n",
      "epoch 1\n",
      "train mean loss=2.2637168118167783, accuracy=0.2116343490304709\n",
      "test  mean loss=1.8683809214916207, accuracy=0.23477297895902546\n",
      "epoch 2\n",
      "train mean loss=2.026476070161011, accuracy=0.20470914127423823\n",
      "test  mean loss=1.7850709283602726, accuracy=0.19712070874861573\n",
      "epoch 3\n",
      "train mean loss=1.9879528922717657, accuracy=0.20664819944598337\n",
      "test  mean loss=1.964937148828179, accuracy=0.25359911406423036\n",
      "epoch 4\n",
      "train mean loss=1.9987345761539532, accuracy=0.2027700831024931\n",
      "test  mean loss=1.797944492411904, accuracy=0.19712070874861573\n",
      "epoch 5\n",
      "train mean loss=2.05381048524809, accuracy=0.21191135734072022\n",
      "test  mean loss=1.9034974403423592, accuracy=0.25802879291251385\n",
      "epoch 6\n",
      "train mean loss=1.9366511823067705, accuracy=0.21024930747922438\n",
      "test  mean loss=1.809968722355062, accuracy=0.17054263565891473\n",
      "epoch 7\n",
      "train mean loss=1.972987536908517, accuracy=0.21634349030470915\n",
      "test  mean loss=1.860296403582838, accuracy=0.2425249169435216\n",
      "epoch 8\n",
      "train mean loss=1.9329091608359212, accuracy=0.1969529085872576\n",
      "test  mean loss=1.7942292011721455, accuracy=0.1849390919158361\n",
      "epoch 9\n",
      "train mean loss=1.9354504265613504, accuracy=0.20470914127423823\n",
      "test  mean loss=1.802772382565115, accuracy=0.2248062015503876\n",
      "epoch 10\n",
      "train mean loss=1.9147644465649887, accuracy=0.19889196675900278\n",
      "test  mean loss=1.8170101212240666, accuracy=0.21483942414174972\n",
      "epoch 1\n",
      "train mean loss=2.2502837162599008, accuracy=0.20581717451523546\n",
      "test  mean loss=1.7609035284944283, accuracy=0.22812846068660023\n",
      "epoch 2\n",
      "train mean loss=2.0573350150829537, accuracy=0.2069252077562327\n",
      "test  mean loss=1.7617343129509708, accuracy=0.23809523809523808\n",
      "epoch 3\n",
      "train mean loss=2.0165990866452375, accuracy=0.2\n",
      "test  mean loss=1.7064318144704285, accuracy=0.15282392026578073\n",
      "epoch 4\n",
      "train mean loss=1.9914472056888146, accuracy=0.20249307479224377\n",
      "test  mean loss=1.957592331557839, accuracy=0.26578073089701\n",
      "epoch 5\n",
      "train mean loss=2.019020928042087, accuracy=0.20110803324099724\n",
      "test  mean loss=1.7190747266327953, accuracy=0.19933554817275748\n",
      "epoch 6\n",
      "train mean loss=1.9654679211222894, accuracy=0.1961218836565097\n",
      "test  mean loss=1.7318336131960848, accuracy=0.150609080841639\n",
      "epoch 7\n",
      "train mean loss=1.966546509338548, accuracy=0.20055401662049863\n",
      "test  mean loss=1.7370034151299054, accuracy=0.14839424141749724\n",
      "epoch 8\n",
      "train mean loss=1.9645748275799104, accuracy=0.19750692520775623\n",
      "test  mean loss=1.6926961985405364, accuracy=0.15503875968992248\n",
      "epoch 9\n",
      "train mean loss=1.994080427809105, accuracy=0.20941828254847644\n",
      "test  mean loss=1.7940690557029952, accuracy=0.14950166112956811\n",
      "epoch 10\n",
      "train mean loss=1.9461957714894471, accuracy=0.20470914127423823\n",
      "test  mean loss=1.8931712702923307, accuracy=0.2646733111849391\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroo/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=2.223566067446569, accuracy=0.20963721960675713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroo/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  mean loss=1.9522346911039161, accuracy=0.25055432372505543\n",
      "epoch 2\n",
      "train mean loss=2.062042019764032, accuracy=0.2079756300193852\n",
      "test  mean loss=1.8322894018135156, accuracy=0.24057649667405764\n",
      "epoch 3\n",
      "train mean loss=2.024869899279653, accuracy=0.20299086125726945\n",
      "test  mean loss=1.8171783349995074, accuracy=0.12971175166297116\n",
      "epoch 4\n",
      "train mean loss=1.9932193349385585, accuracy=0.20852949321517586\n",
      "test  mean loss=1.8515623688962137, accuracy=0.1286031042128603\n",
      "epoch 5\n",
      "train mean loss=2.0244540497392407, accuracy=0.2104680144004431\n",
      "test  mean loss=1.842446756468644, accuracy=0.13082039911308205\n",
      "epoch 6\n",
      "train mean loss=1.9707136447328637, accuracy=0.20382165605095542\n",
      "test  mean loss=1.8142380259782407, accuracy=0.12971175166297116\n",
      "epoch 7\n",
      "train mean loss=1.9754956482322352, accuracy=0.19855995569094434\n",
      "test  mean loss=1.828904280905713, accuracy=0.25055432372505543\n",
      "epoch 8\n",
      "train mean loss=1.9635876212150427, accuracy=0.2093602880088618\n",
      "test  mean loss=1.8291832866795577, accuracy=0.2261640798226164\n",
      "epoch 9\n",
      "train mean loss=1.946412936104727, accuracy=0.19883688728883966\n",
      "test  mean loss=1.8240383300442917, accuracy=0.13082039911308205\n",
      "epoch 10\n",
      "train mean loss=1.9477934085969548, accuracy=0.2063140404320133\n",
      "test  mean loss=1.8006121007407583, accuracy=0.1319290465631929\n",
      "epoch 1\n",
      "train mean loss=2.226099541959126, accuracy=0.2093602880088618\n",
      "test  mean loss=1.9206911793304917, accuracy=0.12084257206208426\n",
      "epoch 2\n",
      "train mean loss=2.050561503999552, accuracy=0.21849903073940738\n",
      "test  mean loss=1.8902271930500039, accuracy=0.1319290465631929\n",
      "epoch 3\n",
      "train mean loss=2.0198522391856724, accuracy=0.20132927166989753\n",
      "test  mean loss=1.9256840936360498, accuracy=0.2361419068736142\n",
      "epoch 4\n",
      "train mean loss=1.9848683340600308, accuracy=0.21019108280254778\n",
      "test  mean loss=1.8854516065305722, accuracy=0.1629711751662971\n",
      "epoch 5\n",
      "train mean loss=1.9975249079976574, accuracy=0.20880642481307118\n",
      "test  mean loss=2.4252437498511337, accuracy=0.25388026607538805\n",
      "epoch 6\n",
      "train mean loss=1.9619752106921424, accuracy=0.2118526723899197\n",
      "test  mean loss=1.8864925113855604, accuracy=0.1164079822616408\n",
      "epoch 7\n",
      "train mean loss=1.9380158736282556, accuracy=0.20576017723622264\n",
      "test  mean loss=2.1575189535475094, accuracy=0.2583148558758315\n",
      "epoch 8\n",
      "train mean loss=1.9326711130155416, accuracy=0.2215452783162559\n",
      "test  mean loss=1.8781987505318585, accuracy=0.1762749445676275\n",
      "epoch 9\n",
      "train mean loss=1.9023939273721193, accuracy=0.2035447244530601\n",
      "test  mean loss=1.9174760069921117, accuracy=0.24944567627494457\n",
      "epoch 10\n",
      "train mean loss=1.9531262381127652, accuracy=0.2132373303793963\n",
      "test  mean loss=1.8908331336044684, accuracy=0.1352549889135255\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_splits = 5\n",
    "studyRate = 0.002\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "description = \"hiroo-\" +str(DATAPOINT)+\"-\"+str(STRIDE_SIZE)+\"-lr-\"+str(studyRate)\n",
    "\n",
    "# datasize=range(ntrial)\n",
    "datasize = range(len(X))\n",
    "trail = 10\n",
    "\n",
    "train_loss_value=np.empty((n_splits, trail))\n",
    "train_acc_value=np.empty((n_splits, trail))\n",
    "test_loss_value=np.empty((n_splits, trail))\n",
    "test_acc_value=np.empty((n_splits, trail))\n",
    "test_acc_each=np.zeros((n_splits, trail, 5))\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(datasize)):\n",
    "#     train_x, train_y = dataAugmentation(eeg[:, :, train_index], emotions[:, train_index], DATAPOINT, STRIDE_SIZE, fs)\n",
    "#     test_x, test_y = dataAugmentation(eeg[:, :, test_index], emotions[:, test_index,], DATAPOINT, STRIDE_SIZE, fs)\n",
    "    train_x, train_y = X[train_index], Y[train_index]\n",
    "    test_x, test_y = X[test_index], Y[test_index]\n",
    "    traindataset = EmotionDataManager(train_x, train_y)\n",
    "    testdataset = EmotionDataManager(test_x, test_y)\n",
    "    trainloader = DataLoader(traindataset, batch_size,shuffle=True, num_workers=0)\n",
    "    testloader = DataLoader(testdataset, batch_size,shuffle=True, num_workers=0)\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = CNN()\n",
    "    model = net.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=studyRate)\n",
    "    for epoch in range(trail):\n",
    "        print('epoch', epoch+1)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "\n",
    "        net.train()\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "#             print(\"===============\")\n",
    "#             print(i)\n",
    "#             print(\"===============\")\n",
    "            loss = criterion(outputs, labels)\n",
    "#             l2_lambda = 0.0001\n",
    "#             l2_norm = sum(p.pow(2.0).sum()\n",
    "#                           for p in model.parameters())\n",
    "\n",
    "#             loss = loss + l2_lambda * l2_norm\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ## softmaxをかませる\n",
    "            sum_loss += loss.item()                     \n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += acc(outputs, labels, 0.5).sum().item()\n",
    "\n",
    "        print(\"train mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(trainloader.dataset), float(sum_correct/sum_total)))\n",
    "        train_loss_value[fold, epoch] = sum_loss*batch_size/len(trainloader.dataset)\n",
    "        train_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "        \n",
    "#         label_each = np.zeros(5)\n",
    "#         acc_each = np.zeros(5)\n",
    "\n",
    "        net.eval()\n",
    "        for i, (inputs, labels) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            sum_loss += loss.item()                     \n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += acc(outputs, labels, 0.5).sum().item()\n",
    "            \n",
    "#             for l, lab in enumerate(labels):\n",
    "#                 label_each[lab] += 1\n",
    "#                 if (predicted[l] == lab):\n",
    "#                     acc_each[lab] += 1\n",
    "\n",
    "        print(\"test  mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(testloader.dataset), float(sum_correct/sum_total)))\n",
    "        test_loss_value[fold, epoch] = sum_loss*batch_size/len(testloader.dataset)\n",
    "        test_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "#         for lab in range(5):\n",
    "#             if  label_each[lab] > 0:\n",
    "#                 test_acc_each[fold, epoch, lab] = acc_each[lab] / label_each[lab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dbd5f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw=0.5\n",
    "outputs = outputs.reshape(-1)\n",
    "labels = labels.reshape(-1)\n",
    "c1 = outputs > labels-bw\n",
    "c2 = outputs < labels+bw\n",
    "result = np.zeros(c1.shape, dtype=bool)\n",
    "for i in range(len(c1)):\n",
    "    if c1[i]  and c2[i]:\n",
    "        result[i] = True        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e311e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "680d14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_y)\n",
    "plt.savefig('../results/hiroo/cnn/hist.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "571ca6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.0444],\n",
       "         [2.1898],\n",
       "         [1.8879],\n",
       "         [2.1043],\n",
       "         [2.3795],\n",
       "         [2.4689],\n",
       "         [2.0080],\n",
       "         [2.5236],\n",
       "         [2.7248],\n",
       "         [1.8992],\n",
       "         [2.3171],\n",
       "         [2.3911],\n",
       "         [2.4274],\n",
       "         [2.6134],\n",
       "         [3.0121],\n",
       "         [2.5251],\n",
       "         [2.2651],\n",
       "         [2.2157],\n",
       "         [2.8942],\n",
       "         [2.3761],\n",
       "         [2.9083],\n",
       "         [1.9333],\n",
       "         [1.7129],\n",
       "         [2.5337],\n",
       "         [2.0966],\n",
       "         [2.9140],\n",
       "         [2.2911],\n",
       "         [2.0485],\n",
       "         [1.8254],\n",
       "         [2.4503],\n",
       "         [2.4862],\n",
       "         [2.0489]], grad_fn=<AddmmBackward0>),\n",
       " tensor([5.0000, 5.0000, 3.0000, 1.0000, 4.0000, 3.0000, 1.0000, 1.0000, 4.0000,\n",
       "         3.9000, 5.0000, 2.0000, 4.0000, 3.0000, 1.0000, 1.0000, 4.0000, 2.0000,\n",
       "         5.0000, 4.0000, 4.0000, 1.0000, 1.0000, 2.0000, 1.0000, 1.0000, 1.0000,\n",
       "         2.0000, 2.0000, 2.0000, 4.0000, 1.0000]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8103aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(outputs, labels, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90231376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e2d63ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_splits):\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    ax_right = fig.add_subplot(121)\n",
    "    ax_left = fig.add_subplot(122)\n",
    "\n",
    "    x = np.linspace(0, test_loss_value.shape[1], test_loss_value.shape[1], endpoint=False)\n",
    "    ax_right.plot(x, train_loss_value[i, :], label=\"train\")\n",
    "    ax_right.plot(x, test_loss_value[i, :], label=\"test\")\n",
    "    ax_right.set_title(\"Loss at each epoch\",fontsize=32)\n",
    "    ax_right.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_right.set_ylabel(\"Loss\",fontsize=32)\n",
    "    ax_right.tick_params(axis='x', labelsize=24)\n",
    "    ax_right.tick_params(axis='y', labelsize=24)\n",
    "    ax_right.legend()\n",
    "\n",
    "\n",
    "    ax_left.plot(x, train_acc_value[i, :], label=\"train\")\n",
    "    ax_left.plot(x, test_acc_value[i, :], label=\"test\")\n",
    "    ax_left.set_title(\"Accuracy at each epoch\",fontsize=32)\n",
    "    ax_left.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_left.set_ylabel(\"Accuracy rate\",fontsize=32)\n",
    "    ax_left.tick_params(axis='x', labelsize=24)\n",
    "    ax_left.tick_params(axis='y', labelsize=24)\n",
    "    ax_left.legend()\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../results/hiroo/cnn/1127-%s-fold-%d.jpg' % (description, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58e80efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(outputs, labels, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72409fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9783],\n",
       "        [2.9873],\n",
       "        [3.1707],\n",
       "        [3.2907],\n",
       "        [2.9589],\n",
       "        [3.4052]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8337e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1000, 3.1000, 3.2000, 3.1100, 3.1000, 3.1000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb5fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
