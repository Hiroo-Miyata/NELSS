{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78578778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# get filename_list\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2a4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('../data/preprocessed/hiroo-cnn.mat')\n",
    "## load\n",
    "eeg = mat[\"eegData\"]\n",
    "emotions = mat[\"labels\"]\n",
    "emotions = emotions.astype(int)\n",
    "nchannel = eeg.shape[1]\n",
    "ntrial = eeg.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7602b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAugmentation(matrix, labels, DATAPOINT, STRIDE_SIZE, fs): ## able to improve\n",
    "    n_size = int((matrix.shape[0] - DATAPOINT) // STRIDE_SIZE) + 1\n",
    "    augmentedMat = np.empty((n_size*matrix.shape[2], 1, DATAPOINT, matrix.shape[1]))\n",
    "    augmentedLabel = np.empty((n_size*matrix.shape[2]))\n",
    "    for t in range(matrix.shape[-1]):\n",
    "        trial = matrix[:, :, t]\n",
    "        for i in range(n_size):\n",
    "            augmentedMat[i+t*n_size, :, :, :] = trial[i*STRIDE_SIZE:i*STRIDE_SIZE+DATAPOINT, :]\n",
    "            augmentedLabel[i+t*n_size] =  np.mean(labels[i*STRIDE_SIZE:i*STRIDE_SIZE+DATAPOINT])\n",
    "    return augmentedMat, augmentedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546299dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1, 640, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, lab = dataAugmentation(eeg, emotions, 640, 128, 128)\n",
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75cae3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1 , 3.1 , 3.1 , 3.1 , 3.1 , 3.1 , 3.12, 3.14, 3.16, 3.18, 3.2 ,\n",
       "       3.2 , 3.2 , 3.2 , 3.2 , 3.2 , 3.18, 3.16, 3.14, 3.12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecbc6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class EmotionDataManager(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.df = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = torch.tensor(self.label[index]).float()\n",
    "        data = torch.tensor(self.df[index]).float()\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ce5621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## (1, 640, 28)\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, kernel_size=(16, 8), stride=(4,4), padding=(6, 2)),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1)\n",
    "                                  )\n",
    "        ## (16, 160, 7)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=(16,3) , stride=(4,3), padding=(6, 1)),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1),\n",
    "                                  )\n",
    "        ## (32, 40, 3)\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=(9,3) , stride=(1,1), padding=(0, 0)),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.MaxPool2d(1),\n",
    "                                  )\n",
    "        ## (64,32,1)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.50)\n",
    "#         self.dropout2 = torch.nn.Dropout(p=0.50)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(64 * 32 *  1, 128),nn.ReLU(inplace=True),)\n",
    "#         self.fc2 = nn.Sequential(nn.Linear(1024, 64),nn.ReLU(inplace=True),)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x= self.dropout1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x= self.dropout2(x)\n",
    "#         print(x[:, :5])\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31bd22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(outputs, labels, bw):\n",
    "    c1 = outputs > labels-bw\n",
    "    c2 = outputs < labels+bw\n",
    "    \n",
    "    return np.all(np.concatenate((c1,c2), 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141f1a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 1, 640, 29)\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroo/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/hiroo/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=1.795991552400065, accuracy=0.3791208791208791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiroo/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  mean loss=0.5434323457571176, accuracy=0.03296703296703297\n",
      "epoch 2\n",
      "train mean loss=0.4470234493632893, accuracy=0.6277472527472527\n",
      "test  mean loss=0.04776793685588208, accuracy=0.989010989010989\n",
      "epoch 3\n",
      "train mean loss=0.4141244338108943, accuracy=0.6758241758241759\n",
      "test  mean loss=0.032195324426168924, accuracy=0.9945054945054945\n",
      "epoch 4\n",
      "train mean loss=0.39815106758704555, accuracy=0.6758241758241759\n",
      "test  mean loss=0.04437077438438332, accuracy=0.978021978021978\n",
      "epoch 5\n",
      "train mean loss=0.400712401002318, accuracy=0.6771978021978022\n",
      "test  mean loss=0.026873707935050294, accuracy=0.9945054945054945\n",
      "epoch 6\n",
      "train mean loss=0.38883579399559526, accuracy=0.6978021978021978\n",
      "test  mean loss=0.033756590888395416, accuracy=0.9945054945054945\n",
      "epoch 7\n",
      "train mean loss=0.3970518937477699, accuracy=0.6744505494505495\n",
      "test  mean loss=0.03456649364350916, accuracy=0.9945054945054945\n",
      "epoch 8\n",
      "train mean loss=0.38103611652667707, accuracy=0.7019230769230769\n",
      "test  mean loss=0.030560948691525303, accuracy=1.0\n",
      "epoch 9\n",
      "train mean loss=0.3940188400037996, accuracy=0.6826923076923077\n",
      "test  mean loss=0.032712263884125174, accuracy=0.9945054945054945\n",
      "epoch 10\n",
      "train mean loss=0.3837477581186609, accuracy=0.6868131868131868\n",
      "test  mean loss=0.028129858957542168, accuracy=0.9945054945054945\n",
      "epoch 1\n",
      "train mean loss=1.5172197216159695, accuracy=0.40934065934065933\n",
      "test  mean loss=0.5971529876792824, accuracy=0.027472527472527472\n",
      "epoch 2\n",
      "train mean loss=0.42196802975057246, accuracy=0.6483516483516484\n",
      "test  mean loss=0.042753599993475194, accuracy=0.978021978021978\n",
      "epoch 3\n",
      "train mean loss=0.41089878108475236, accuracy=0.6662087912087912\n",
      "test  mean loss=0.05829026509117294, accuracy=0.945054945054945\n",
      "epoch 4\n",
      "train mean loss=0.416365656878922, accuracy=0.657967032967033\n",
      "test  mean loss=0.06608984496567276, accuracy=0.9395604395604396\n",
      "epoch 5\n",
      "train mean loss=0.3760104729579045, accuracy=0.6964285714285714\n",
      "test  mean loss=0.02412664218918308, accuracy=1.0\n",
      "epoch 6\n",
      "train mean loss=0.3767176110010881, accuracy=0.7129120879120879\n",
      "test  mean loss=0.03605610860900565, accuracy=0.989010989010989\n",
      "epoch 7\n",
      "train mean loss=0.38342480541585566, accuracy=0.6991758241758241\n",
      "test  mean loss=0.05860835117298168, accuracy=0.945054945054945\n",
      "epoch 8\n",
      "train mean loss=0.38652895636610934, accuracy=0.6909340659340659\n",
      "test  mean loss=0.0697123103744381, accuracy=0.967032967032967\n",
      "epoch 9\n",
      "train mean loss=0.3778596494224045, accuracy=0.7005494505494505\n",
      "test  mean loss=0.03749753551168756, accuracy=0.989010989010989\n",
      "epoch 10\n",
      "train mean loss=0.37207239538758663, accuracy=0.6978021978021978\n",
      "test  mean loss=0.050868563927136935, accuracy=0.9725274725274725\n",
      "epoch 1\n",
      "train mean loss=1.7570649922549069, accuracy=0.36675824175824173\n",
      "test  mean loss=0.5526903304424915, accuracy=0.054945054945054944\n",
      "epoch 2\n",
      "train mean loss=0.4416937585715409, accuracy=0.625\n",
      "test  mean loss=0.0638185353069515, accuracy=0.9395604395604396\n",
      "epoch 3\n",
      "train mean loss=0.4444063672652611, accuracy=0.6332417582417582\n",
      "test  mean loss=0.0371238125877066, accuracy=0.9835164835164835\n",
      "epoch 4\n",
      "train mean loss=0.41833101524101507, accuracy=0.6442307692307693\n",
      "test  mean loss=0.047445277263829994, accuracy=0.989010989010989\n",
      "epoch 5\n",
      "train mean loss=0.4201898961276798, accuracy=0.6730769230769231\n",
      "test  mean loss=0.04295085599789253, accuracy=0.9945054945054945\n",
      "epoch 6\n",
      "train mean loss=0.40136335970281245, accuracy=0.6758241758241759\n",
      "test  mean loss=0.03318063358029166, accuracy=0.9945054945054945\n",
      "epoch 7\n",
      "train mean loss=0.4047949294467549, accuracy=0.6497252747252747\n",
      "test  mean loss=0.029944262088655114, accuracy=0.9945054945054945\n",
      "epoch 8\n",
      "train mean loss=0.38373754902200385, accuracy=0.7032967032967034\n",
      "test  mean loss=0.04581000958825206, accuracy=0.978021978021978\n",
      "epoch 9\n",
      "train mean loss=0.39725859479589776, accuracy=0.6813186813186813\n",
      "test  mean loss=0.037577927440077395, accuracy=0.9835164835164835\n",
      "epoch 10\n",
      "train mean loss=0.3975312549334306, accuracy=0.6634615384615384\n",
      "test  mean loss=0.029942369968681545, accuracy=0.989010989010989\n",
      "epoch 1\n",
      "train mean loss=1.4637217482367715, accuracy=0.40934065934065933\n",
      "test  mean loss=0.413979729453286, accuracy=0.10989010989010989\n",
      "epoch 2\n",
      "train mean loss=0.44540932872793176, accuracy=0.625\n",
      "test  mean loss=0.041748183932933176, accuracy=0.967032967032967\n",
      "epoch 3\n",
      "train mean loss=0.4254109034171471, accuracy=0.6401098901098901\n",
      "test  mean loss=0.032154777220317295, accuracy=0.989010989010989\n",
      "epoch 4\n",
      "train mean loss=0.39804963030657925, accuracy=0.6744505494505495\n",
      "test  mean loss=0.059947771685464044, accuracy=0.9395604395604396\n",
      "epoch 5\n",
      "train mean loss=0.4061811841451205, accuracy=0.6634615384615384\n",
      "test  mean loss=0.03318907402373932, accuracy=0.9835164835164835\n",
      "epoch 6\n",
      "train mean loss=0.3828683384172209, accuracy=0.679945054945055\n",
      "test  mean loss=0.030838688978782065, accuracy=0.9945054945054945\n",
      "epoch 7\n",
      "train mean loss=0.3739774796988938, accuracy=0.7211538461538461\n",
      "test  mean loss=0.03270584705111745, accuracy=0.9945054945054945\n",
      "epoch 8\n",
      "train mean loss=0.36080052564432336, accuracy=0.7266483516483516\n",
      "test  mean loss=0.030829846531480222, accuracy=0.9945054945054945\n",
      "epoch 9\n",
      "train mean loss=0.38085797592833803, accuracy=0.6978021978021978\n",
      "test  mean loss=0.030963983673315782, accuracy=0.989010989010989\n",
      "epoch 10\n",
      "train mean loss=0.3643516167834565, accuracy=0.7101648351648352\n",
      "test  mean loss=0.029431219611849104, accuracy=1.0\n",
      "epoch 1\n",
      "train mean loss=1.64067524933553, accuracy=0.3901098901098901\n",
      "test  mean loss=0.5832420338641157, accuracy=0.054945054945054944\n",
      "epoch 2\n",
      "train mean loss=0.4690659576719934, accuracy=0.5892857142857143\n",
      "test  mean loss=0.05297378360570132, accuracy=0.9285714285714286\n",
      "epoch 3\n",
      "train mean loss=0.4505945175558656, accuracy=0.6016483516483516\n",
      "test  mean loss=0.12466442126494187, accuracy=0.7527472527472527\n",
      "epoch 4\n",
      "train mean loss=0.45701509222879516, accuracy=0.5975274725274725\n",
      "test  mean loss=0.041646101808809975, accuracy=0.967032967032967\n",
      "epoch 5\n",
      "train mean loss=0.42502140016346185, accuracy=0.6373626373626373\n",
      "test  mean loss=0.03244745559417284, accuracy=0.9725274725274725\n",
      "epoch 6\n",
      "train mean loss=0.4147105636177482, accuracy=0.6428571428571429\n",
      "test  mean loss=0.03226715342684106, accuracy=0.989010989010989\n",
      "epoch 7\n",
      "train mean loss=0.4069097081383506, accuracy=0.6565934065934066\n",
      "test  mean loss=0.025103768149575035, accuracy=0.989010989010989\n",
      "epoch 8\n",
      "train mean loss=0.4217385590731443, accuracy=0.6620879120879121\n",
      "test  mean loss=0.029223436510169898, accuracy=0.989010989010989\n",
      "epoch 9\n",
      "train mean loss=0.3950674022947039, accuracy=0.6758241758241759\n",
      "test  mean loss=0.02847833472948808, accuracy=0.989010989010989\n",
      "epoch 10\n",
      "train mean loss=0.4018267399662144, accuracy=0.6813186813186813\n",
      "test  mean loss=0.058265387356936274, accuracy=0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "## Input\n",
    "fs = 128\n",
    "tw = 5\n",
    "DATAPOINT = fs*tw\n",
    "STRIDE_SIZE = fs//2\n",
    "batch_size = 16\n",
    "n_splits = 5\n",
    "studyRate = 0.0001\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "description = \"hiroo-\" +str(DATAPOINT)+\"-\"+str(STRIDE_SIZE)+\"-lr-\"+str(studyRate)\n",
    "\n",
    "X, Y = dataAugmentation(eeg, emotions, DATAPOINT, STRIDE_SIZE, fs)\n",
    "print(X.shape)\n",
    "trail = 10\n",
    "\n",
    "train_loss_value=np.empty((n_splits, trail))\n",
    "train_acc_value=np.empty((n_splits, trail))\n",
    "test_loss_value=np.empty((n_splits, trail))\n",
    "test_acc_value=np.empty((n_splits, trail))\n",
    "test_acc_each=np.zeros((n_splits, trail, 5))\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    train_x, train_y = X[train_index], Y[train_index]\n",
    "    test_x, test_y = X[test_index], Y[test_index]\n",
    "    traindataset = EmotionDataManager(train_x, train_y)\n",
    "    testdataset = EmotionDataManager(test_x, test_y)\n",
    "    trainloader = DataLoader(traindataset, batch_size,shuffle=True, num_workers=0)\n",
    "    testloader = DataLoader(testdataset, batch_size,shuffle=True, num_workers=0)\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = CNN()\n",
    "    model = net.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=studyRate)\n",
    "    for epoch in range(trail):\n",
    "        print('epoch', epoch+1)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "\n",
    "        net.train()\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "#             print(\"===============\")\n",
    "#             print(i)\n",
    "#             print(\"===============\")\n",
    "            loss = criterion(outputs, labels)\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "                          for p in model.parameters())\n",
    "\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ## softmaxをかませる\n",
    "            sum_loss += loss.item()                     \n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += acc(outputs, labels, 0.5).sum().item()\n",
    "\n",
    "        print(\"train mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(trainloader.dataset), float(sum_correct/sum_total)))\n",
    "        train_loss_value[fold, epoch] = sum_loss*batch_size/len(trainloader.dataset)\n",
    "        train_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "        \n",
    "#         label_each = np.zeros(5)\n",
    "#         acc_each = np.zeros(5)\n",
    "\n",
    "        net.eval()\n",
    "        for i, (inputs, labels) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            sum_loss += loss.item()                     \n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += acc(outputs, labels, 0.5).sum().item()\n",
    "            \n",
    "#             for l, lab in enumerate(labels):\n",
    "#                 label_each[lab] += 1\n",
    "#                 if (predicted[l] == lab):\n",
    "#                     acc_each[lab] += 1\n",
    "\n",
    "        print(\"test  mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(testloader.dataset), float(sum_correct/sum_total)))\n",
    "        test_loss_value[fold, epoch] = sum_loss*batch_size/len(testloader.dataset)\n",
    "        test_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "#         for lab in range(5):\n",
    "#             if  label_each[lab] > 0:\n",
    "#                 test_acc_each[fold, epoch, lab] = acc_each[lab] / label_each[lab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de36721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(outputs, labels, 0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e52420b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[True, True], [True, False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b44ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab5fa095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f63bf991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_14582/3456356805.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_splits):\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    ax_right = fig.add_subplot(121)\n",
    "    ax_left = fig.add_subplot(122)\n",
    "\n",
    "    x = np.linspace(0, test_loss_value.shape[1], test_loss_value.shape[1], endpoint=False)\n",
    "    ax_right.plot(x, train_loss_value[i, :], label=\"train\")\n",
    "    ax_right.plot(x, test_loss_value[i, :], label=\"test\")\n",
    "    ax_right.set_title(\"Loss at each epoch\",fontsize=32)\n",
    "    ax_right.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_right.set_ylabel(\"Loss\",fontsize=32)\n",
    "    ax_right.tick_params(axis='x', labelsize=24)\n",
    "    ax_right.tick_params(axis='y', labelsize=24)\n",
    "    ax_right.legend()\n",
    "\n",
    "\n",
    "    ax_left.plot(x, train_acc_value[i, :], label=\"train\")\n",
    "    ax_left.plot(x, test_acc_value[i, :], label=\"test\")\n",
    "    ax_left.set_title(\"Accuracy at each epoch\",fontsize=32)\n",
    "    ax_left.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_left.set_ylabel(\"Accuracy rate\",fontsize=32)\n",
    "    ax_left.tick_params(axis='x', labelsize=24)\n",
    "    ax_left.tick_params(axis='y', labelsize=24)\n",
    "    ax_left.legend()\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../results/hiroo/cnn/1127-%s-fold-%d.jpg' % (description, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83e90eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(outputs, labels, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "345e8058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9783],\n",
       "        [2.9873],\n",
       "        [3.1707],\n",
       "        [3.2907],\n",
       "        [2.9589],\n",
       "        [3.4052]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b2a3dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1000, 3.1000, 3.2000, 3.1100, 3.1000, 3.1000])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b88be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
