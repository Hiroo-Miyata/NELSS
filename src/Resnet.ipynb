{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1e573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# get filename_list\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3f20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('../data/preprocessed/resnet50.mat')\n",
    "## load\n",
    "X = mat[\"preprocessedData\"]\n",
    "Y = mat[\"meanlabels\"]\n",
    "ntrial = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84490ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 3, 224, 224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8cc172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c7ab8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class EmotionDataManager(Dataset):\n",
    "    def __init__(self, data, label, transforms):\n",
    "        self.df = data\n",
    "        self.label = label.squeeze(1)\n",
    "        self.transforms = transforms;\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = torch.tensor(self.label[index]-1).long()\n",
    "        data = torch.tensor(self.df[index]).float()\n",
    "#         print(\"hoge\")\n",
    "#         data = self.transforms(data)\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b03350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "744f53e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 3, 224, 224)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8eb7a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "----------\n",
      "train mean loss=1.661678564750542, accuracy=0.29661017656326294\n",
      "test  mean loss=1.5286946773529053, accuracy=0.36666667461395264\n",
      "epoch 2\n",
      "----------\n",
      "train mean loss=1.1535967891499148, accuracy=0.6101694703102112\n",
      "test  mean loss=1.655027707417806, accuracy=0.36666667461395264\n",
      "epoch 3\n",
      "----------\n",
      "train mean loss=0.6464260195271444, accuracy=0.7966101765632629\n",
      "test  mean loss=1.8733041922251383, accuracy=0.36666667461395264\n",
      "epoch 4\n",
      "----------\n",
      "train mean loss=0.5472180012424114, accuracy=0.8559321761131287\n",
      "test  mean loss=2.21662784020106, accuracy=0.23333333432674408\n",
      "epoch 5\n",
      "----------\n",
      "train mean loss=0.6113801063117335, accuracy=0.7542372941970825\n",
      "test  mean loss=1.6233549992243448, accuracy=0.46666666865348816\n",
      "epoch 6\n",
      "----------\n",
      "train mean loss=0.6338315176761756, accuracy=0.7881355881690979\n",
      "test  mean loss=2.101747751235962, accuracy=0.2666666805744171\n",
      "epoch 7\n",
      "----------\n",
      "train mean loss=0.5107162185644699, accuracy=0.8220338821411133\n",
      "test  mean loss=2.0721645673116047, accuracy=0.2666666805744171\n",
      "epoch 8\n",
      "----------\n",
      "train mean loss=0.4457287251696748, accuracy=0.8305084705352783\n",
      "test  mean loss=1.8711864312489828, accuracy=0.30000001192092896\n",
      "epoch 9\n",
      "----------\n",
      "train mean loss=0.283231025024996, accuracy=0.9322034120559692\n",
      "test  mean loss=1.8373858372370402, accuracy=0.30000001192092896\n",
      "epoch 10\n",
      "----------\n",
      "train mean loss=0.25088665495484563, accuracy=0.9322034120559692\n",
      "test  mean loss=1.8746613581975302, accuracy=0.23333333432674408\n",
      "epoch 1\n",
      "----------\n",
      "train mean loss=1.6621745279279805, accuracy=0.19491524994373322\n",
      "test  mean loss=1.7102383772532146, accuracy=0.2666666805744171\n",
      "epoch 2\n",
      "----------\n",
      "train mean loss=1.2597608667309002, accuracy=0.5254237055778503\n",
      "test  mean loss=1.74087815284729, accuracy=0.30000001192092896\n",
      "epoch 3\n",
      "----------\n",
      "train mean loss=0.683462320748022, accuracy=0.805084764957428\n",
      "test  mean loss=1.923103427886963, accuracy=0.2666666805744171\n",
      "epoch 4\n",
      "----------\n",
      "train mean loss=0.5477809097807286, accuracy=0.8305084705352783\n",
      "test  mean loss=1.8100121815999348, accuracy=0.2666666805744171\n",
      "epoch 5\n",
      "----------\n",
      "train mean loss=0.5135468963091656, accuracy=0.8220338821411133\n",
      "test  mean loss=1.8832913398742677, accuracy=0.36666667461395264\n",
      "epoch 6\n",
      "----------\n",
      "train mean loss=0.5288280081951012, accuracy=0.7966101765632629\n",
      "test  mean loss=2.42518044312795, accuracy=0.2666666805744171\n",
      "epoch 7\n",
      "----------\n",
      "train mean loss=0.49926861640760456, accuracy=0.805084764957428\n",
      "test  mean loss=2.4924483140309652, accuracy=0.3333333432674408\n",
      "epoch 8\n",
      "----------\n",
      "train mean loss=0.38495797518703895, accuracy=0.8728813529014587\n",
      "test  mean loss=1.8886492649714153, accuracy=0.3333333432674408\n",
      "epoch 9\n",
      "----------\n",
      "train mean loss=0.21997684966457093, accuracy=0.9406779408454895\n",
      "test  mean loss=1.975940465927124, accuracy=0.3333333432674408\n",
      "epoch 10\n",
      "----------\n",
      "train mean loss=0.33557979181661446, accuracy=0.8898305296897888\n",
      "test  mean loss=1.6769604444503785, accuracy=0.36666667461395264\n",
      "epoch 1\n",
      "----------\n",
      "train mean loss=1.654888387453758, accuracy=0.26271185278892517\n",
      "test  mean loss=1.7728568077087403, accuracy=0.2666666805744171\n",
      "epoch 2\n",
      "----------\n",
      "train mean loss=1.176899772579387, accuracy=0.5254237055778503\n",
      "test  mean loss=1.7925075531005858, accuracy=0.4000000059604645\n",
      "epoch 3\n",
      "----------\n",
      "train mean loss=0.8797686554617801, accuracy=0.6694915294647217\n",
      "test  mean loss=2.0895972569783527, accuracy=0.23333333432674408\n",
      "epoch 4\n",
      "----------\n",
      "train mean loss=0.5221508711071338, accuracy=0.8305084705352783\n",
      "test  mean loss=1.8125979105631511, accuracy=0.46666666865348816\n",
      "epoch 5\n",
      "----------\n",
      "train mean loss=0.48380928246651667, accuracy=0.805084764957428\n",
      "test  mean loss=2.4837151447931927, accuracy=0.20000000298023224\n",
      "epoch 6\n",
      "----------\n",
      "train mean loss=0.6315343491101669, accuracy=0.7966101765632629\n",
      "test  mean loss=1.7084466218948364, accuracy=0.5\n",
      "epoch 7\n",
      "----------\n",
      "train mean loss=0.4687792032451953, accuracy=0.8559321761131287\n",
      "test  mean loss=1.7366952816645305, accuracy=0.4333333373069763\n",
      "epoch 8\n",
      "----------\n",
      "train mean loss=0.39401202200580454, accuracy=0.8898305296897888\n",
      "test  mean loss=1.7183810393015544, accuracy=0.4000000059604645\n",
      "epoch 9\n",
      "----------\n",
      "train mean loss=0.33009629867086976, accuracy=0.8644067645072937\n",
      "test  mean loss=2.0418918689092, accuracy=0.36666667461395264\n",
      "epoch 10\n",
      "----------\n",
      "train mean loss=0.2638775461306006, accuracy=0.9406779408454895\n",
      "test  mean loss=1.7270842432975768, accuracy=0.36666667461395264\n",
      "epoch 1\n",
      "----------\n",
      "train mean loss=1.5702549269219406, accuracy=0.2857142984867096\n",
      "test  mean loss=1.7963271634332065, accuracy=0.3103448152542114\n",
      "epoch 2\n",
      "----------\n",
      "train mean loss=1.044296475017772, accuracy=0.6386554837226868\n",
      "test  mean loss=1.8086683996792496, accuracy=0.3448275923728943\n",
      "epoch 3\n",
      "----------\n",
      "train mean loss=0.584760633085956, accuracy=0.7983193397521973\n",
      "test  mean loss=1.8986154918012947, accuracy=0.3448275923728943\n",
      "epoch 4\n",
      "----------\n",
      "train mean loss=0.45972384024067087, accuracy=0.8403361439704895\n",
      "test  mean loss=2.446011683036541, accuracy=0.3103448152542114\n",
      "epoch 5\n",
      "----------\n",
      "train mean loss=0.5967837279083348, accuracy=0.7815126180648804\n",
      "test  mean loss=2.2688102568018027, accuracy=0.3103448152542114\n",
      "epoch 6\n",
      "----------\n",
      "train mean loss=0.4493674206383088, accuracy=0.831932783126831\n",
      "test  mean loss=2.4543325120005113, accuracy=0.3103448152542114\n",
      "epoch 7\n",
      "----------\n",
      "train mean loss=0.38220070459011224, accuracy=0.8571428656578064\n",
      "test  mean loss=2.312706306062896, accuracy=0.3448275923728943\n",
      "epoch 8\n",
      "----------\n",
      "train mean loss=0.32721842362099335, accuracy=0.9159663915634155\n",
      "test  mean loss=2.532207258816423, accuracy=0.37931033968925476\n",
      "epoch 9\n",
      "----------\n",
      "train mean loss=0.1890724648197158, accuracy=0.9663865566253662\n",
      "test  mean loss=2.175823182895266, accuracy=0.3448275923728943\n",
      "epoch 10\n",
      "----------\n",
      "train mean loss=0.3732022084608799, accuracy=0.8823529481887817\n",
      "test  mean loss=2.1401474825267135, accuracy=0.3448275923728943\n",
      "epoch 1\n",
      "----------\n",
      "train mean loss=1.6626073853308414, accuracy=0.2521008551120758\n",
      "test  mean loss=1.5808116156479408, accuracy=0.4482758641242981\n",
      "epoch 2\n",
      "----------\n",
      "train mean loss=1.1293470518929618, accuracy=0.6218487620353699\n",
      "test  mean loss=1.5981098865640575, accuracy=0.4137931168079376\n",
      "epoch 3\n",
      "----------\n",
      "train mean loss=0.7650347467230147, accuracy=0.7226890921592712\n",
      "test  mean loss=2.169537034528009, accuracy=0.3103448152542114\n",
      "epoch 4\n",
      "----------\n",
      "train mean loss=0.6707604998300055, accuracy=0.7899159789085388\n",
      "test  mean loss=2.1960752914691795, accuracy=0.3103448152542114\n",
      "epoch 5\n",
      "----------\n",
      "train mean loss=0.6291141156889811, accuracy=0.8067227005958557\n",
      "test  mean loss=2.144388100196575, accuracy=0.27586206793785095\n",
      "epoch 6\n",
      "----------\n",
      "train mean loss=0.6025942030574093, accuracy=0.8151260614395142\n",
      "test  mean loss=2.377733723870639, accuracy=0.27586206793785095\n",
      "epoch 7\n",
      "----------\n",
      "train mean loss=0.4045482530814259, accuracy=0.8571428656578064\n",
      "test  mean loss=2.251660338763533, accuracy=0.3103448152542114\n",
      "epoch 8\n",
      "----------\n",
      "train mean loss=0.520327336898371, accuracy=0.8151260614395142\n",
      "test  mean loss=1.6467169441025833, accuracy=0.4137931168079376\n",
      "epoch 9\n",
      "----------\n",
      "train mean loss=0.22657591592864829, accuracy=0.9579831957817078\n",
      "test  mean loss=1.9108709302441826, accuracy=0.37931033968925476\n",
      "epoch 10\n",
      "----------\n",
      "train mean loss=0.23019389864526876, accuracy=0.9327731132507324\n",
      "test  mean loss=1.8350146721149314, accuracy=0.3448275923728943\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "description = \"1129-resnet50-sgd-lr-0.001\"\n",
    "\n",
    "# datasize=range(ntrial)\n",
    "datasize = range(ntrial)\n",
    "epoches = 10\n",
    "\n",
    "train_loss_value=np.empty((n_splits, epoches))\n",
    "train_acc_value=np.empty((n_splits, epoches))\n",
    "test_loss_value=np.empty((n_splits, epoches))\n",
    "test_acc_value=np.empty((n_splits, epoches))\n",
    "test_acc_each=np.zeros((n_splits, epoches, 5*5));\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(datasize)):\n",
    "    train_x, train_y = X[train_index], Y[train_index]\n",
    "    test_x, test_y = X[test_index], Y[test_index]\n",
    "    traindataset = EmotionDataManager(train_x, train_y, data_transforms)\n",
    "    testdataset = EmotionDataManager(test_x, test_y, data_transforms)\n",
    "    trainloader = DataLoader(traindataset, batch_size,shuffle=True, num_workers=0)\n",
    "    testloader = DataLoader(testdataset, batch_size,shuffle=True, num_workers=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 5)\n",
    "    model_ft = model_ft.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        print('epoch', epoch+1)\n",
    "        print('-' * 10)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "\n",
    "        model_ft.train()\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer_ft.zero_grad()\n",
    "            outputs = model_ft(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "#             l2_lambda = 0.0001\n",
    "#             l2_norm = sum(p.pow(2.0).sum()\n",
    "#                           for p in model.parameters())\n",
    "#             loss = loss + l2_lambda * l2_norm\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        exp_lr_scheduler.step()\n",
    "        \n",
    "        print(\"train mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(trainloader.dataset), float(sum_correct/sum_total)))\n",
    "        train_loss_value[fold, epoch] = sum_loss*batch_size/len(trainloader.dataset)\n",
    "        train_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "        \n",
    "#         label_each = np.zeros(5)\n",
    "#         acc_each = np.zeros(5)\n",
    "\n",
    "        model_ft.eval()\n",
    "        for i, (inputs, labels) in enumerate(testloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer_ft.zero_grad()\n",
    "            outputs = model_ft(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            sum_total += labels.size(0)                 \n",
    "            sum_correct += torch.sum(preds == labels)\n",
    "            \n",
    "#             for l, lab in enumerate(labels):\n",
    "#                 label_each[lab] += 1\n",
    "#                 if (predicted[l] == lab):\n",
    "#                     acc_each[lab] += 1\n",
    "\n",
    "        print(\"test  mean loss={}, accuracy={}\".format(sum_loss*batch_size/len(testloader.dataset), float(sum_correct/sum_total)))\n",
    "        test_loss_value[fold, epoch] = sum_loss*batch_size/len(testloader.dataset)\n",
    "        test_acc_value[fold, epoch] = float(sum_correct/sum_total)\n",
    "#         for lab in range(5):\n",
    "#             if  label_each[lab] > 0:\n",
    "#                 test_acc_each[fold, epoch, lab] = acc_each[lab] / label_each[lab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5acb47f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 5]), torch.Size([1, 16]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, labels.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6108a9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7235, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(outputs, labels.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b89be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f12c96f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_44940/2403428781.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_44940/2403428781.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_44940/2403428781.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_44940/2403428781.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/jh/nkpm2xxn2qdbzyljrfx984m40000gn/T/ipykernel_44940/2403428781.py:28: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_splits):\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    ax_right = fig.add_subplot(121)\n",
    "    ax_left = fig.add_subplot(122)\n",
    "\n",
    "    x = np.linspace(0, test_loss_value.shape[1], test_loss_value.shape[1], endpoint=False)\n",
    "    ax_right.plot(x, train_loss_value[i, :], label=\"train\")\n",
    "    ax_right.plot(x, test_loss_value[i, :], label=\"test\")\n",
    "    ax_right.set_title(\"Loss at each epoch\",fontsize=32)\n",
    "    ax_right.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_right.set_ylabel(\"Loss\",fontsize=32)\n",
    "    ax_right.tick_params(axis='x', labelsize=24)\n",
    "    ax_right.tick_params(axis='y', labelsize=24)\n",
    "    ax_right.legend()\n",
    "\n",
    "\n",
    "    ax_left.plot(x, train_acc_value[i, :], label=\"train\")\n",
    "    ax_left.plot(x, test_acc_value[i, :], label=\"test\")\n",
    "    ax_left.set_title(\"Accuracy at each epoch\",fontsize=32)\n",
    "    ax_left.set_xlabel(\"Epoch\",fontsize=32)\n",
    "    ax_left.set_ylabel(\"Accuracy rate\",fontsize=32)\n",
    "    ax_left.tick_params(axis='x', labelsize=24)\n",
    "    ax_left.tick_params(axis='y', labelsize=24)\n",
    "    ax_left.legend()\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../results/hiroo/cnn/%s-fold-%d.jpg' % (description, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4402d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
